{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "# GLOBALS\n",
    "# vot_path = \"../../../vot2016/\"\n",
    "vot_path = \"/home/zabulskyy/Datasets/vot2016/\"\n",
    "# yolo_pred_path = \"../yolo_predictions/extended\"\n",
    "yolo_pred_path = \"/mnt/sshfs/YOLO-tracker/yolo_predictions/extended\"\n",
    "crit_vals = {\n",
    "    \"iou\": 1,\n",
    "    \"dist2\": 1,\n",
    "#     \"abs_pos\": 1,\n",
    "#     \"rel_pos\": 1,\n",
    "    \"cc\": 100,  # class_correspondence\n",
    "}\n",
    "with open(\"../../yoloTorch/data/coco.names\", \"r\") as f:\n",
    "    classes = f.read().split(\"\\n\")[:-1]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file=\"correlations.csv\"):\n",
    "    with open(file, 'r') as file:\n",
    "        l = file.read().split(\"\\n\")\n",
    "        l.pop(-1)\n",
    "        l = [[float(x) for x in y.split(\",\")[:-1]] for y in l]   \n",
    "        return torch.tensor(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist2(row1, row2):\n",
    "    pass\n",
    "\n",
    "def the_closest(row_to_compare, rows):\n",
    "    pass\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    pass\n",
    "\n",
    "def the_most_iou(row_to_compare, rows):\n",
    "    pass\n",
    "\n",
    "def interpolate(data):\n",
    "    pass\n",
    "\n",
    "def read_gt(vot_class, vot_path=vot_path, force_square=True):\n",
    "    pass\n",
    "\n",
    "def read_yolo_pred(vot_class, yolo_pred_path=yolo_pred_path, force_square=True):\n",
    "    pass\n",
    "\n",
    "def eval_energy(bb1, bb2, cv=crit_vals):\n",
    "    pass\n",
    "\n",
    "def class_correlations(class_probs1, class_probs2):\n",
    "    pass\n",
    "\n",
    "def eval_class_corr(cls1, cls2, correlations=cm):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist2(row1, row2):\n",
    "    x11, y11, x12, y12 = row1[1:5] if len(row1) != 4 else row1[:]\n",
    "    x21, y21, x22, y22 = row2[1:5] if len(row2) != 4 else row2[:]\n",
    "    x1, y1 = (x11 + x12) / 2, (y11 + y12) / 2\n",
    "    x2, y2 = (x21 + x22) / 2, (y21 + y22) / 2\n",
    "    X = (x1 - x2) ** 2\n",
    "    Y = (y1 - y2) ** 2\n",
    "    res = float((X + Y) ** 0.5)\n",
    "    return res\n",
    "def the_closest(row_to_compare, rows):\n",
    "    m, i = np.infty, 0\n",
    "    for n, row in enumerate(rows):\n",
    "        d = dist2(row, row_to_compare)\n",
    "        if d < m:\n",
    "            m = float(d)\n",
    "            i = n\n",
    "    return rows[i], i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxA, boxB):\n",
    "    boxA = boxA[1:5] if len(boxA) != 4 else boxA\n",
    "    boxB = boxB[1:5] if len(boxB) != 4 else boxB\n",
    "\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    res = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return res\n",
    "def the_most_iou(row_to_compare, rows):\n",
    "    M, i = 0, 0\n",
    "    for n, row in enumerate(rows):\n",
    "        v = iou(row, row_to_compare)\n",
    "        if v > M:\n",
    "            M = float(v)\n",
    "            i = n\n",
    "    return rows[i], i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subframes(row1, row2, width):\n",
    "    frame1, frame2 = int(row1[0]), int(row2[0])\n",
    "    diff = frame1 - frame2\n",
    "    if diff == 1:\n",
    "        return None\n",
    "    result = torch.zeros((frame2 - frame1 - 1, width))\n",
    "    # result[:, -1] = row1[-1]\n",
    "    step = (row1 - row2) / diff\n",
    "    for frame_n in range(frame2 - frame1 - 1):\n",
    "        result[frame_n] = row1 + (step) * (frame_n + 1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def merge_frames(*rows):\n",
    "    result = torch.zeros((1, 8))\n",
    "    n = len(rows)\n",
    "    for row in rows:\n",
    "        result += row\n",
    "    return result / n\n",
    "\n",
    "\n",
    "def the_closest(row_to_compare, rows):\n",
    "    def dist(row1, row2):\n",
    "        x11, y11, x12, y12 = row1[1:5] if len(row1) != 4 else row1[:]\n",
    "        x21, y21, x22, y22 = row2[1:5] if len(row2) != 4 else row2[:]\n",
    "        x1, y1 = (x11 + x12) / 2, (y11 + y12) / 2\n",
    "        x2, y2 = (x21 + x22) / 2, (y21 + y22) / 2\n",
    "        X = (x1 - x2) ** 2\n",
    "        Y = (y1 - y2) ** 2\n",
    "        res = float((X + Y) ** 0.5)\n",
    "        return res\n",
    "\n",
    "    m, i = np.infty, 0\n",
    "    for n, row in enumerate(rows):\n",
    "        d = dist(row, row_to_compare)\n",
    "        if d < m:\n",
    "            m = float(d)\n",
    "            i = n\n",
    "    return rows[i], i\n",
    "\n",
    "def fill_first(tensor):\n",
    "    FIRST = tensor[0]\n",
    "    for i in range(int(FIRST[0]) - 1, -1, -1):\n",
    "        row = FIRST\n",
    "        row[0] = i\n",
    "        row = row.view((1, -1))\n",
    "        tensor = torch.cat((row, tensor))\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def fill_last(tensor, NUM_FRAMES):\n",
    "    last = tensor[tensor[:, 0] != 0][-1]\n",
    "    for i in range(int(last[0]) + 1, NUM_FRAMES):\n",
    "        row = last\n",
    "        row[0] = i\n",
    "        row = row.view((1, -1))\n",
    "        tensor[i] = row\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def most_frequent_class(results):\n",
    "    counts = np.bincount(results[:, -1])\n",
    "    return np.argmax(counts)\n",
    "\n",
    "\n",
    "def interpolate(data):\n",
    "    \"\"\"\n",
    "    interpolate gaps\n",
    "    choose one detection among multiple, by picking the closest one by the euclidean distance\n",
    "    ignore class labels\n",
    "    :param OUTPUT: tensor\n",
    "    :param NUM_FRAMES:\n",
    "    :param CUDA: bool - if cuda is available\n",
    "    :return: interpolated tensor\n",
    "    \"\"\"\n",
    "    OUTPUT = data[\"output\"]\n",
    "    NUM_FRAMES = data[\"num_frames\"]\n",
    "    CUDA = data[\"CUDA\"]\n",
    "\n",
    "    width = OUTPUT.size()[1]\n",
    "    result = torch.zeros((NUM_FRAMES, width))\n",
    "    if CUDA:\n",
    "        result = result.cuda()\n",
    "\n",
    "    if OUTPUT[0][0] != 0:\n",
    "        OUTPUT = fill_first(OUTPUT)\n",
    "\n",
    "    output_iter = 0\n",
    "    res_iter = 0\n",
    "    while res_iter != NUM_FRAMES:\n",
    "        if (output_iter > len(OUTPUT) - 1):\n",
    "            # break\n",
    "            result = fill_last(result, NUM_FRAMES)\n",
    "            break\n",
    "        if output_iter == OUTPUT.shape[0] - 1:\n",
    "            result[res_iter] = OUTPUT[output_iter]\n",
    "            output_iter += 1\n",
    "            res_iter += 1\n",
    "            continue\n",
    "\n",
    "        # next frame is interpolated\n",
    "        if OUTPUT[output_iter][0] == OUTPUT[output_iter + 1][0] - 1:\n",
    "            result[res_iter] = OUTPUT[output_iter]\n",
    "            output_iter += 1\n",
    "            res_iter += 1\n",
    "            continue\n",
    "\n",
    "        # missing detection on some frames, fill with missing\n",
    "        if OUTPUT[output_iter][0] + 1 < OUTPUT[output_iter + 1][0]:\n",
    "            subframes = generate_subframes(\n",
    "                OUTPUT[output_iter], OUTPUT[output_iter + 1], width)\n",
    "            result[res_iter] = OUTPUT[output_iter]\n",
    "            for subframe in subframes:\n",
    "                res_iter += 1\n",
    "                result[res_iter] = subframe\n",
    "            output_iter += 1\n",
    "            res_iter += 1\n",
    "            continue\n",
    "\n",
    "        # this frame contains multiple detections, have to choose one\n",
    "        if OUTPUT[output_iter][0] == OUTPUT[output_iter + 1][0]:\n",
    "            frame = OUTPUT[output_iter][0]\n",
    "            to_cut = OUTPUT[OUTPUT[:, 0] == frame]\n",
    "            # closest, _ = the_closest(result[res_iter - 1], to_cut)\n",
    "            # result[res_iter] = closest\n",
    "            closest, _ = the_most_iou(result[res_iter - 1], to_cut)\n",
    "            result[res_iter] = closest\n",
    "\n",
    "            output_iter += len(to_cut)\n",
    "            res_iter += 1\n",
    "\n",
    "            if output_iter >= OUTPUT.shape[0] - 1:\n",
    "                break\n",
    "\n",
    "            # missing detection on some frames, fill with missing\n",
    "            if OUTPUT[output_iter - 1][0] + 1 < OUTPUT[output_iter][0]:\n",
    "                subframes = generate_subframes(\n",
    "                    result[res_iter - 1], OUTPUT[output_iter], width)\n",
    "                # result[res_iter] = OUTPUT[output_iter]\n",
    "                for subframe in subframes:\n",
    "                    result[res_iter] = subframe\n",
    "                    res_iter += 1\n",
    "            continue\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_first_frame(to_replace, OUTPUT):\n",
    "    OUTPUT = OUTPUT[OUTPUT[:, 0] != 0]\n",
    "    return torch.cat((to_replace.view((1, -1)), OUTPUT))\n",
    "\n",
    "def pp_first(data):\n",
    "    # detects the closest object to FIRST gt box and removes the rest on the FIRST frame\n",
    "    CUDA = data[\"CUDA\"]\n",
    "    output = data[\"output\"]\n",
    "    first = data[\"first\"]\n",
    "\n",
    "    tcc, _ = the_most_iou(first, output)\n",
    "    # only detections close to the true FIRST frame\n",
    "    output = replace_first_frame(tcc, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gt(vot_class, vot_path=vot_path, force_square=True):\n",
    "    gt_file = osp.join(vot_path, vot_class, \"groundtruth.txt\")\n",
    "    with open(gt_file, 'r') as file:\n",
    "        l =file.read().split(\"\\n\")\n",
    "        l.pop(-1)\n",
    "        l = [[float(x) for x in y.split(\",\")] for y in l]\n",
    "        if force_square:\n",
    "            l = [[min(m[::2]), min(m[1::2]), max(m[::2]), max(m[1::2])] for m in l]   \n",
    "        return torch.tensor(l)\n",
    "    \n",
    "def read_full_gt(vot_path=vot_path, force_square=True):\n",
    "    vot_classes = [x for x in os.listdir(vot_path) if not x.endswith(\".txt\")]\n",
    "    X = list()\n",
    "    for vot_class in vot_classes:\n",
    "        gt_file = osp.join(vot_path, vot_class, \"groundtruth.txt\")\n",
    "        with open(gt_file, 'r') as file:\n",
    "            l =file.read().split(\"\\n\")\n",
    "            l.pop(-1)\n",
    "            l = [[float(x) for x in y.split(\",\")] for y in l]\n",
    "            if force_square:\n",
    "                l = [[min(m[::2]), min(m[1::2]), max(m[::2]), max(m[1::2])] for m in l]   \n",
    "        X.append(l)\n",
    "    return torch.tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yolo_pred(vot_class, yolo_pred_path=yolo_pred_path, pred_format=\"csv\", first_len=True):\n",
    "    yolo_pred_file = osp.join(yolo_pred_path, vot_class + \".\" + pred_format)\n",
    "    with open(yolo_pred_file, 'r') as file:\n",
    "        l =file.read().split(\"\\n\")\n",
    "        l.pop(-1)\n",
    "        im_len = -1\n",
    "        if first_len:\n",
    "            im_len = float(l.pop(0))\n",
    "        l = [[float(x) for x in y.split(\",\")] for y in l]            \n",
    "        return torch.tensor(l), im_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class correlation\n",
    "def ccc(classes_probs):\n",
    "    # classes_probs.shape = (bboxes, classes)\n",
    "    corr_mat = torch.zeros((classes_probs.shape[1], classes_probs.shape[1], ))\n",
    "\n",
    "    for cls in range(len(classes_probs[0])):\n",
    "        col = classes_probs[:, cls].view((-1, 1))\n",
    "        tX = col * classes_probs\n",
    "        sX = torch.sum(tX, dim=0)\n",
    "        corr_mat[cls] = sX\n",
    "    return corr_mat\n",
    "\n",
    "def corr(col1, col2):\n",
    "    mean1, mean2 = torch.mean(col1), torch.mean(col2)\n",
    "    cm1, cm2 = col1 - mean1, col2 - mean2\n",
    "    top = sum(cm1 * cm2)\n",
    "    bot = torch.sqrt(sum(cm1 ** 2) * sum(cm2 ** 2))\n",
    "    return top / bot\n",
    "\n",
    "# compute class correlation coefficient\n",
    "def cccc(classes_probs):\n",
    "    # classes_probs.shape = (bboxes, classes)\n",
    "    corr_mat = torch.zeros((classes_probs.shape[1], classes_probs.shape[1], ))\n",
    "    num_classes = len(classes_probs[0])\n",
    "    for cls1 in range(num_classes):\n",
    "        col1 = classes_probs[:, cls1].view((-1, 1))\n",
    "        for cls2 in range(cls1 + 1, num_classes):\n",
    "            print(\"{}.{} / {}\".format(cls1+1, cls2+1, num_classes))\n",
    "            col2 = classes_probs[:, cls2].view((-1, 1))\n",
    "            _corr = corr(col1, col2)\n",
    "#             _corr = np.corrcoef(col1, col2)\n",
    "            corr_mat[cls1, cls2] = _corr\n",
    "    return corr_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_yolo_preds(path=yolo_pred_path, pred_format=\"csv\"):\n",
    "    X = []\n",
    "    for vot_class in os.listdir(path):\n",
    "        yolo_pred_file = osp.join(path, vot_class)\n",
    "        with open(yolo_pred_file, 'r') as file:\n",
    "            l = file.read().split(\"\\n\")\n",
    "            l.pop(-1)\n",
    "            l.pop(0)\n",
    "            im_len = -1\n",
    "            for i in l:\n",
    "                X.append([float(x) for x in i.split(\",\")])\n",
    "    X = torch.tensor(X)\n",
    "#     cls_probs = X[:, 6:]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_single_class_corr(cls1 : int, cls2 : int, correlations=cm):\n",
    "    return float(cm[cls1][cls2])\n",
    "\n",
    "def eval_whole_class_corr(cls1, cls2, correlations=cm):\n",
    "    # TODO: consider if this worth it\n",
    "    # too complicated yet\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(tensor):\n",
    "    mean = torch.mean(tensor)\n",
    "    std = torch.std(tensor)\n",
    "    return (tensor - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(matrix, file=\"correlations.csv\"):\n",
    "    for i in matrix.tolist():\n",
    "        for j in i:\n",
    "            print(j, sep=\", \", end=\", \", file=open(file, \"a+\"))\n",
    "        print(file=open(file, \"a+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_i = classes.index(\"orange\")\n",
    "# cm_vals = torch.sort(cm[class_i], descending=True)[0]\n",
    "# cm_idxs = torch.sort(cm[class_i], descending=True)[1]\n",
    "\n",
    "# i = 0\n",
    "# while i != 80:\n",
    "#     print(classes[cm_idxs[i]], \"\\t\\t\" , float(cm_vals[i]))\n",
    "#     i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_energy(bb1, bb2, cv=crit_vals):\n",
    "    box1, box2 = bb1[1:5], bb2[1:5]\n",
    "    cls1, cls2 = bb1[6: ], bb2[6: ]  # 5'th column is the precision of the bbox\n",
    "    class1, class2 = torch.argmax(cls1), torch.argmax(cls2)\n",
    "    \n",
    "    _iou = iou(box1, box2)\n",
    "    _cc = max(0, eval_single_class_corr(class1, class2))\n",
    "    _dist2 = dist2(box1, box2)  # probably not\n",
    "    \n",
    "    return cv[\"iou\"] * _iou, cv[\"cc\"] * _cc, cv[\"dist2\"] * _dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cebtf(frame1, frame2):  # calc_energies_between_two_frames\n",
    "    boxes = torch.zeros((len(frame1)))\n",
    "    energies = torch.zeros((len(frame1)))\n",
    "    for i in range(len(frame1)):\n",
    "        max_energy = 0\n",
    "        max_energy_index = 0\n",
    "        for j in range(len(frame2)):\n",
    "            energy = eval_energy(frame1[i], frame2[j])\n",
    "            energy = energy[0] + energy[1]  # iou and class correspondence\n",
    "            if energy > max_energy:\n",
    "                max_energy = energy\n",
    "                max_energy_index = j\n",
    "        boxes[i] = max_energy_index\n",
    "        energies[i] = max_energy\n",
    "    return boxes, energies\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_res = dict()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " soccer1\n",
      "energies\n",
      "34.6% 69.5% \n",
      "interpolation\n",
      "tensor([ 300.7100,  135.5500,  371.7500,  219.9700]) tensor([[   0.0000,  265.0144,    4.0887,  566.5678,  360.0000],\n",
      "        [   2.0000,  251.9438,   16.2566,  575.1027,  353.0335],\n",
      "        [   3.0000,  243.1795,   28.1014,  577.6489,  353.6281],\n",
      "        ...,\n",
      "        [ 389.0000,  309.5993,   74.0018,  524.3060,  354.6740],\n",
      "        [ 390.0000,  305.7798,   79.9999,  521.1733,  353.2141],\n",
      "        [ 391.0000,  315.4599,   77.5337,  518.9969,  357.6635]])\n",
      "tensor([[ 182.0000,  308.7520,  177.5748,  391.6583,  239.2658],\n",
      "        [   2.0000,  251.9438,   16.2566,  575.1027,  353.0335],\n",
      "        [   3.0000,  243.1795,   28.1014,  577.6489,  353.6281],\n",
      "        ...,\n",
      "        [ 389.0000,  309.5993,   74.0018,  524.3060,  354.6740],\n",
      "        [ 390.0000,  305.7798,   79.9999,  521.1733,  353.2141],\n",
      "        [ 391.0000,  315.4599,   77.5337,  518.9969,  357.6635]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 392 is out of bounds for dimension 0 with size 392",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-310-0379dfc929bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mtotal_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvot_class\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-276-bea36d473979>\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msubframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mres_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres_iter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0moutput_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mres_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 392 is out of bounds for dimension 0 with size 392"
     ]
    }
   ],
   "source": [
    "def get_first(vot_class):\n",
    "    with open(osp.join(vot_path, vot_class, \"groundtruth.txt\"), 'r') as file:\n",
    "        l = [float(x) for x in file.read().split(\"\\n\")[0].split(\",\")]\n",
    "        X, Y = l[::2], l[1::2]\n",
    "        l = [min(X), min(Y), max(X), max(Y)]\n",
    "        l = torch.tensor([float(x) for x in l])\n",
    "        return l\n",
    "\n",
    "for vot_class in [\"soccer1\"]: #[x for x in os.listdir(vot_path) if not x.endswith(\".txt\")]:  \n",
    "\n",
    "    print(\"\\n\", vot_class)\n",
    "    yp, imlen = read_yolo_pred(vot_class)  # yolo predictions\n",
    "    frames_with_detection = sorted(list(set(yp[:,0].tolist())))\n",
    "    ffwdi = frames_with_detection[0]  # first_frame_with_detection_index\n",
    "    first_boxes = yp[yp[:, 0] == ffwdi]\n",
    "    path = torch.zeros((len(first_boxes), imlen))\n",
    "    energies = torch.zeros((len(first_boxes), imlen))\n",
    "    path.shape, energies.shape\n",
    "    prev_boxes = first_boxes\n",
    "    path[:, 0] = first_boxes[0][0]\n",
    "\n",
    "    # calculate energies\n",
    "    print(\"energies\")\n",
    "    for n, i in enumerate(frames_with_detection[:]):\n",
    "        if n % 100 == 99:\n",
    "            print(str(n / len(frames_with_detection[1:]) * 100)[:4], end=\"% \")\n",
    "        i_boxes = yp[yp[:, 0] == i]\n",
    "        boxes, energy = cebtf(prev_boxes, i_boxes)\n",
    "        path[:, int(n)] = boxes\n",
    "        energies[:, int(n)] = energy\n",
    "        prev_boxes = i_boxes[boxes.long()]\n",
    "    # path, energies\n",
    "    verdict = torch.sum(energies, dim=1)\n",
    "\n",
    "    first_bb_candidates = (verdict == torch.max(verdict)).nonzero().view(-1).tolist()\n",
    "    res_i = path[first_bb_candidates].view(-1).int()\n",
    "    len(res_i), len(frames_with_detection)\n",
    "    res = torch.zeros((len(frames_with_detection), 5))\n",
    "\n",
    "    # prepare for interpolation\n",
    "    for n, i in enumerate(frames_with_detection[:]):\n",
    "        cfp = yp[yp[:, 0] == i]  # current_frame_predictions\n",
    "        index = res_i[n]\n",
    "        cp = cfp[index] # chosen_prediction\n",
    "        res[int(n)] = cp[:5]\n",
    "        \n",
    "    data = dict()\n",
    "    data[\"output\"] = res\n",
    "    data[\"num_frames\"] = int(imlen)\n",
    "    data[\"CUDA\"] = CUDA\n",
    "    data[\"first\"] = get_first(vot_class)\n",
    "    \n",
    "    print(\"\\ninterpolation\")\n",
    "    print(data[\"output\"] )\n",
    "    \n",
    "    total_res[vot_class] = interpolate(data)[:, 1:].tolist()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 300.7100,  135.5500,  371.7500,  219.9700])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"first\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blanket', 'bolt2', 'traffic', 'ball1', 'leaves', 'pedestrian1', 'singer3', 'helicopter', 'godfather'])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12153, 86])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(res, folder, ext=\"csv\", nm_fr=None):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    for name in res:\n",
    "        if nm_fr is not None:\n",
    "            print(nm_fr[name], file=open(osp.join(folder, name + \".\" + ext), 'w+'))\n",
    "            print(\"\\n\".join([\",\".join([str(a) for a in x]) for x in res[name]]),\n",
    "                  file=open(osp.join(folder, name + \".\" + ext), 'a'))\n",
    "        else:\n",
    "            print(\"\\n\".join([\",\".join([str(a) for a in x]) for x in res[name]]),\n",
    "                  file=open(osp.join(folder, name + \".\" + ext), 'w+'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(total_res, \"first_results_more_cc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0.0000,  294.8584,  360.7994,  379.0862,  575.9958],\n",
       "        [   1.0000,  303.0713,  359.6979,  385.3262,  576.0000],\n",
       "        [   2.0000,  307.9651,  358.7937,  388.3065,  575.8509],\n",
       "        ...,\n",
       "        [ 399.0000,  286.9731,  300.8241,  337.3255,  400.4477],\n",
       "        [ 400.0000,  281.9034,  307.2825,  335.9633,  401.4847],\n",
       "        [ 401.0000,  278.1752,  309.6931,  332.9856,  396.9450]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pp_first() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-ed210c277153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpp_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: pp_first() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
