{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T13:41:01.524767Z",
     "start_time": "2018-10-26T13:41:00.887770Z"
    }
   },
   "outputs": [],
   "source": [
    "from detector import predict\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from postprocess import postprocess\n",
    "from args import arg_parse\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2\n",
    "from util import *\n",
    "import os\n",
    "import os.path as osp\n",
    "from darknet import Darknet\n",
    "from preprocess import prep_image, inp_to_image\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle as pkl\n",
    "import itertools\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../darknet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T13:41:01.530035Z",
     "start_time": "2018-10-26T13:41:01.526404Z"
    }
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.bs = 1\n",
    "        self.confidence = .5\n",
    "        self.cfgfile = \"cfg/yolov3.cfg\"\n",
    "        self.nms_thresh = .4\n",
    "        self.weightsfile = \"../yolov3.weights\"\n",
    "        self.images = None\n",
    "        self.reso = \"416\"\n",
    "        self.scales = \"1,2,3\"\n",
    "        self.saveto = \"\"\n",
    "        self.silent = None\n",
    "        self.cuda = \"3\"\n",
    "        self.det = \"det\"\n",
    "        self.vot = \"/home/zabulskyy/data/vot2016/\"\n",
    "        self.pp = \"first_and_mfc_smart\"\n",
    "        self.saveto = \"lol.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T14:05:18.709893Z",
     "start_time": "2018-10-26T14:05:09.384033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network.....\n",
      "Network successfully loaded\n",
      "\n",
      "processing bmx\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "vot_path = args.vot\n",
    "saveto = args.saveto\n",
    "# pp = None if args.pp.lower() == \"none\" else args.pp\n",
    "\n",
    "cuda_n = int(args.cuda)\n",
    "silent = args.silent == \"all\"\n",
    "if (silent):\n",
    "    import sys\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "batch_size = int(args.bs)\n",
    "confidence = float(args.confidence)\n",
    "nms_thesh = float(args.nms_thresh)\n",
    "start = 0\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.cuda\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "classes = load_classes('data/coco.names')\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Set up the neural network\n",
    "print(\"Loading network.....\")\n",
    "model = Darknet(args.cfgfile)\n",
    "model.load_weights(args.weightsfile)\n",
    "print(\"Network successfully loaded\")\n",
    "\n",
    "model.net_info[\"height\"] = args.reso\n",
    "inp_dim = int(model.net_info[\"height\"])\n",
    "assert inp_dim % 32 == 0\n",
    "assert inp_dim > 32\n",
    "\n",
    "# If there's a GPU availible, put the model on GPU\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "print()\n",
    "# Detection phase\n",
    "\n",
    "vot_path = args.vot\n",
    "saveto = args.saveto\n",
    "\n",
    "folder = \"bmx\"\n",
    "\n",
    "result = dict()\n",
    "num_frames = dict()\n",
    "\n",
    "images = osp.join(vot_path, folder)\n",
    "if (not os.path.isdir(images)):\n",
    "    print(folder, \"is not a folder\")\n",
    "    exit()\n",
    "\n",
    "print(\"processing {}\".format(folder))\n",
    "\n",
    "try:\n",
    "    imlist = [osp.join(osp.realpath('.'), images, img) for img in sorted(\n",
    "        os.listdir(images))[:] if os.path.splitext(\n",
    "        img)[1] == '.png' or os.path.splitext(\n",
    "        img)[1] == '.jpeg' or os.path.splitext(img)[1] == '.jpg']\n",
    "except NotADirectoryError:\n",
    "    imlist = []\n",
    "    imlist.append(osp.join(osp.realpath('.'), images))\n",
    "except FileNotFoundError:\n",
    "    print(\"No file or directory with the name {}\".format(images))\n",
    "    exit()\n",
    "\n",
    "num_frames[folder] = len(imlist)\n",
    "\n",
    "batches = list(\n",
    "    map(prep_image, imlist, [inp_dim for x in range(len(imlist))]))\n",
    "im_batches = [x[0] for x in batches]\n",
    "orig_ims = [x[1] for x in batches]\n",
    "\n",
    "if batch_size != 1:\n",
    "    num_batches = len(imlist) // batch_size + leftover\n",
    "    im_batches = [torch.cat((\n",
    "        im_batches[i*batch_size: min((i + 1)*batch_size,\n",
    "        len(im_batches))])) for i in range(num_batches)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T14:05:18.709893Z",
     "start_time": "2018-10-26T14:05:09.384033Z"
    }
   },
   "outputs": [],
   "source": [
    "# [ block for block in model.blocks if block[\"type\"] == \"convolutional\"][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T14:05:18.709893Z",
     "start_time": "2018-10-26T14:05:09.384033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=81\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "i=93\n",
      "torch.Size([1, 512, 26, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zabulskyy/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=105\n",
      "torch.Size([1, 256, 52, 52])\n",
      "from darknet, emb: torch.Size([1, 8112, 256])\n",
      "from darknet, emb_detections: [torch.Size([1, 507, 1024]), torch.Size([1, 2028, 512]), torch.Size([1, 8112, 256])]\n",
      "from darknet, x: torch.Size([1, 8112, 85])\n",
      "from darknet, detections: torch.Size([1, 10647, 85])\n",
      "torch.Size([1, 10647, 85])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "batch = im_batches[0]\n",
    "\n",
    "'''=====detection pahse====='''\n",
    "\n",
    "if CUDA:\n",
    "    batch = batch.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction, embed = model.forward(Variable(batch), CUDA)\n",
    "print(prediction.shape)\n",
    "\n",
    "prediction = write_results(\n",
    "    prediction, confidence, num_classes, nms=True, nms_conf=nms_thesh)\n",
    "\n",
    "if type(prediction) == int:\n",
    "    i += 1\n",
    "#     continue\n",
    "prediction[:, 0] += i*batch_size\n",
    "\n",
    "for im_num, image in enumerate(imlist[i*batch_size: min((i + 1)*batch_size, len(imlist))]):\n",
    "    im_id = i*batch_size + im_num\n",
    "    objs = [classes[int(x[-1])] for x in prediction if int(x[0]) == im_id]\n",
    "\n",
    "i += 1\n",
    "\n",
    "if CUDA:\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "im_dim_list = [x[2] for x in batches]\n",
    "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1, 2)\n",
    "\n",
    "if CUDA:\n",
    "    im_dim_list = im_dim_list.cuda()\n",
    "\n",
    "im_dim_list = torch.index_select(im_dim_list, 0, prediction[:, 0].long())\n",
    "scaling_factor = torch.min(inp_dim/im_dim_list, 1)[0].view(-1, 1)\n",
    "prediction[:, [1, 3]] -= (inp_dim - scaling_factor * im_dim_list[:, 0].view(-1, 1)) / 2\n",
    "prediction[:, [2, 4]] -= (inp_dim - scaling_factor * im_dim_list[:, 1].view(-1, 1)) / 2\n",
    "prediction[:, 1:5] /= scaling_factor\n",
    "\n",
    "for j in range(prediction.shape[0]):\n",
    "    prediction[j, [1, 3]] = torch.clamp(\n",
    "        prediction[j, [1, 3]], 0.0, im_dim_list[j, 0])\n",
    "    prediction[j, [2, 4]] = torch.clamp(\n",
    "        prediction[j, [2, 4]], 0.0, im_dim_list[j, 1])\n",
    "\n",
    "# '''=====plotting====='''\n",
    "\n",
    "# im = Image.open(image)\n",
    "# plt.imshow(im)\n",
    "# plt.title(image.split('/')[-1])\n",
    "# for pr_bb in prediction[:, 1:5]:\n",
    "#     X, Y = pr_bb[::2], pr_bb[1::2]\n",
    "#     pr_bb = [min(X), min(Y), max(X),  max(Y)]\n",
    "#     plt.plot([pr_bb[0], pr_bb[2], pr_bb[2], pr_bb[0], pr_bb[0], ],\n",
    "#                          [pr_bb[1], pr_bb[1], pr_bb[3], pr_bb[3], pr_bb[1], ], 'r-', lw=2)\n",
    "# plt.show()\n",
    "# plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d188ef484af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "embed.shape, prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 net\n",
      "1 convolutional\n",
      "2 convolutional\n",
      "3 convolutional\n",
      "4 convolutional\n",
      "5 shortcut\n",
      "6 convolutional\n",
      "7 convolutional\n",
      "8 convolutional\n",
      "9 shortcut\n",
      "10 convolutional\n",
      "11 convolutional\n",
      "12 shortcut\n",
      "13 convolutional\n",
      "14 convolutional\n",
      "15 convolutional\n",
      "16 shortcut\n",
      "17 convolutional\n",
      "18 convolutional\n",
      "19 shortcut\n",
      "20 convolutional\n",
      "21 convolutional\n",
      "22 shortcut\n",
      "23 convolutional\n",
      "24 convolutional\n",
      "25 shortcut\n",
      "26 convolutional\n",
      "27 convolutional\n",
      "28 shortcut\n",
      "29 convolutional\n",
      "30 convolutional\n",
      "31 shortcut\n",
      "32 convolutional\n",
      "33 convolutional\n",
      "34 shortcut\n",
      "35 convolutional\n",
      "36 convolutional\n",
      "37 shortcut\n",
      "38 convolutional\n",
      "39 convolutional\n",
      "40 convolutional\n",
      "41 shortcut\n",
      "42 convolutional\n",
      "43 convolutional\n",
      "44 shortcut\n",
      "45 convolutional\n",
      "46 convolutional\n",
      "47 shortcut\n",
      "48 convolutional\n",
      "49 convolutional\n",
      "50 shortcut\n",
      "51 convolutional\n",
      "52 convolutional\n",
      "53 shortcut\n",
      "54 convolutional\n",
      "55 convolutional\n",
      "56 shortcut\n",
      "57 convolutional\n",
      "58 convolutional\n",
      "59 shortcut\n",
      "60 convolutional\n",
      "61 convolutional\n",
      "62 shortcut\n",
      "63 convolutional\n",
      "64 convolutional\n",
      "65 convolutional\n",
      "66 shortcut\n",
      "67 convolutional\n",
      "68 convolutional\n",
      "69 shortcut\n",
      "70 convolutional\n",
      "71 convolutional\n",
      "72 shortcut\n",
      "73 convolutional\n",
      "74 convolutional\n",
      "75 shortcut\n",
      "76 convolutional\n",
      "77 convolutional\n",
      "78 convolutional\n",
      "79 convolutional\n",
      "80 convolutional\n",
      "81 convolutional\n",
      "82 convolutional\n",
      "83 yolo\n",
      "84 route\n",
      "85 convolutional\n",
      "86 upsample\n",
      "87 route\n",
      "88 convolutional\n",
      "89 convolutional\n",
      "90 convolutional\n",
      "91 convolutional\n",
      "92 convolutional\n",
      "93 convolutional\n",
      "94 convolutional\n",
      "95 yolo\n",
      "96 route\n",
      "97 convolutional\n",
      "98 upsample\n",
      "99 route\n",
      "100 convolutional\n",
      "101 convolutional\n",
      "102 convolutional\n",
      "103 convolutional\n",
      "104 convolutional\n",
      "105 convolutional\n",
      "106 convolutional\n",
      "107 yolo\n"
     ]
    }
   ],
   "source": [
    "for n, i in enumerate(model.blocks):\n",
    "    print(n, i[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
